# -*- coding: utf-8 -*-
"""Kopie von Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ONNcUjBJnnO-PdODeMs-gVvZEp1o9-mM
"""

import pandas as pd
import torch
from torch.utils.data import TensorDataset
from torch.utils.data import DataLoader
from torch import nn
from torch.nn import functional as F #<-- activation function of the neural net
import matplotlib.pyplot as plt

#prepare training and test data

train_data=pd.read_csv('sample_data/california_housing_train.csv')
test_data=pd.read_csv('sample_data/california_housing_test.csv')
#print(train_data)

X_train_np=train_data.to_numpy()[:,:-1] #consider only the first 8 columns as inputs
y_train_np=train_data.to_numpy()[:,-1] #consider the last column "median_house_value" as the output to be estimated
#X_train_np.shape, y_train_np.shape

X_test_np=test_data.to_numpy()[:,:-1] #same procedure for test data
y_test_np=test_data.to_numpy()[:,-1] #same procedure for test data



train_dataset=TensorDataset(torch.tensor(X_train_np, dtype=torch.float), torch.tensor(y_train_np.reshape((-1,1)),dtype=torch.float))
#print(train_dataset)

test_dataset=TensorDataset(torch.tensor(X_test_np, dtype=torch.float), torch.tensor(y_test_np.reshape((-1,1)),dtype=torch.float))
#print(test_dataset)


train_dataloader=DataLoader(train_dataset, batch_size=700)
#for X, y in train_dataloader:
 # print(X.shape, y.shape)
  #break

test_dataloader=DataLoader(test_dataset, batch_size=50)
#for X, y in test_dataloader:
 # print(X.shape, y.shape)
  #break

#Prepare the Network class

class NeuralNet(nn.Module):
  def __init__(self):
    super().__init__()
    self.hidden1=nn.Linear(8,18) #8 Inputs and 18 Neurons in the hidden layer 1
    self.hidden1_activation=nn.ReLU()
    self.hidden2=nn.Linear(18,12) #12 Neurons in the hidden layer 2
    self.hidden2_activation=nn.ReLU()
    self.out=nn.Linear(12,1)

  def forward(self, x):
    x=self.hidden1(x)
    x=self.hidden1_activation(x)
    x=self.hidden2(x)
    x=self.hidden2_activation(x)
    x=self.out(x)
    return x

model=NeuralNet()
#print(model)

loss_fn=nn.MSELoss()
optimizer=torch.optim.Adam(model.parameters(), lr=0.01)

#Train the Model
model.train()

num_itr=400 #number of iteration

for epoch in range(num_itr):
  train_loss=0
  for i, (X,y) in enumerate(train_dataloader):
    y_hat=model(X)
    mse=loss_fn(y_hat,y)
    optimizer.zero_grad()
    mse.backward() #backpropagation to calculate gradients
    train_loss +=mse.item() #accumulating error prediction
    optimizer.step()
  print("epoch: ", epoch, "train_loss: ", train_loss/len(train_dataloader))

"""Test the Model"""


running_loss =0
for i, (X_test,y_test) in enumerate(test_dataloader):
    y_hat=model(X_test)
    mse=loss_fn(y_hat,y_test)
    running_loss +=mse.item()
    #print("y_hat: ", y_hat, "y_test:", y_test, "errors: ", running_loss/len(test_dataloader))

y_hat = model(X_test).detach()
plt.plot(y_hat, 'ro')
plt.plot(y_test, 'b')
plt.xlabel("Count")
plt.ylabel("Average Price")
plt.title("Comparison between predicted (red) and test data (blue)")
#plt.plot(y_test, y_pred, 'b')
#plt.plot(y_hat)
plt.show()